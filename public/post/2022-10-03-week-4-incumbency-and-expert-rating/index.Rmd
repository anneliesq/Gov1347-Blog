---
title: 'Week 4: Expert Ratings'
author: "Annelies Quinton"
date: '2022-10-03'
output:
  pdf_document: default
  html_document:
    df_print: paged
categories: []
tags: []
slug: []
---
This week, I looked at the role of expert rankings at a district level. This is an extension to last week’s focus on polling and incorporating variables into my model that have credibility from others in the election predicting sphere. The questions that directed my research this week were: how accurate are expert rankings, how can expert rankings be compared to actual vote share, and what does this comparison look like at a district level?  

# Data and Steps
This week I looked at three data sets. The first set looked at party vote share on the distinct level. This data allowed me to create a vote share margin variable between republicans and democrats. The second set looked at expert rankings from various sites for each district. The significant variable in this st is average rankings, which takes the average of the rankings on a scale of 1-7 (Solid D to Solid R). Finally, I looked at incumbency data for each district. This shows if the incumbent or challenger won for that district. For all data, I looked at the most recent midterm, filtering the data to 2018. 

```{r setup, include = F}
# Hide code output
knitr::opts_chunk$set(echo = FALSE)
# Loading Packages
install.packages("tidyverse", repos = "http://cran.us.r-project.org")
library(tidyverse)
install.packages("ggplot2", repos = "http://cran.us.r-project.org")
library(ggplot2)

#install.packages("blogdown", repos = "http://cran.us.r-project.org")
install.packages("blogdown", repos = "http://cran.us.r-project.org")
library(blogdown)
install.packages("lubridate", repos = "http://cran.us.r-project.org")
library(lubridate)
install.packages("janitor", repos = "http://cran.us.r-project.org")
library(janitor)
library(usmap)
library(rmapshaper)
library(sf)
install.packages("usdata", repos = "http://cran.us.r-project.org")
library(usdata)

# Geographic data
get_congress_map <- function(cong=114) {
tmp_file <- tempfile()
tmp_dir <- tempdir()
zp <- sprintf("https://cdmaps.polisci.ucla.edu/shp/districts114.zip",cong)
download.file(zp, tmp_file)
unzip(zipfile = tmp_file, exdir = tmp_dir)
fpath <- paste(tmp_dir, sprintf("districtShapes/districts114.shp",cong), sep = "/")
st_read(fpath)
}


# District Vote Share
historical_vs <- read_csv("house party vote share by district 1948 to 2020.csv") %>% 
  filter(raceYear == 2018) %>% 
  select(R_vote_margin, district_num, State, RepVotesMajorPercent, DemVotesMajorPercent) %>% 
  mutate(voteshare_margin = RepVotesMajorPercent - DemVotesMajorPercent)

# 114th congress
cd114 <- get_congress_map(114)
cd114 <- cd114 %>%
  mutate(district_num = DISTRICT) %>% 
  mutate(State = STATENAME) %>% 
  mutate(district_num = as.numeric(district_num)) %>% 
  select(district_num, State) %>% 
  na.omit

cd114_map <- cd114 %>% 
  left_join(historical_vs, by=c("district_num", "State"))
cd114_map$district_num[437]
cd114_simp <- ms_simplify(cd114_map, keep = 0.01, keep_shapes = T)
```

# Mapping Vote Share

The map below shows the actual vote share across the districts in 2018. The color scale goes from red (high Republican vote share) to blue (high Democratic vote share). It is evident that most districts fall in the middle of the gradient because of their lighter colors. Geographically, there appears to be a higher concentration of red districts in the middle of the country, and more blue towards the coasts. 

```{r, include = T}
ggplot() +
  geom_sf(data = cd114_simp, aes(fill = voteshare_margin),
          inherit.aes = FALSE, alpha = 0.9) +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", 
                       limits = c(-100, 100),
                       name = "Vote Share Margin") +
  theme_void() + 
  coord_sf(xlim = c(-172.27, -66.57), ylim = c(18.55, 71.23), expand = FALSE) + 
  labs(title = "Vote Share Margin by District (2018)",
       subtitle = "Republican (Red) -- Democrat (Blue)") +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())
```

# Mapping Expert Rankings
```{r, include = F}

expert_ratings <- read_csv("2018_ratings_share.csv") %>% 
  separate(District, into = c("State", "district_num"), sep = "-") %>% 
  mutate(district_num = as.numeric(district_num)) %>% 
  mutate(State = abbr2state(State)) %>% 
  select('State', 'district_num', 'avg')

incumbent <- read_csv("incumb_dist_1948-2020 (3).csv") %>% 
  filter(year == 2018) %>% 
  mutate(district_num = as.numeric(district_num)) %>%
  mutate(State = state) %>% 
  select(State, district_num, RepVotesMajorPercent, DemVotesMajorPercent, winner_candidate_inc)

expert_incumbent <- incumbent %>% 
  left_join(expert_ratings, by = c('State', 'district_num')) %>% 
  mutate(Rankings_code = case_when(
    avg < 1.5 ~ 60,
    avg >= 1.5 & avg < 2.5 ~ 55,
    avg >= 2.5 & avg < 3.5  ~ 52.5,
    avg >= 3.5 & avg < 4.5 ~ 50,
    avg >= 4.5 & avg < 5.5 ~ 47.5,
    avg >= 5.5 & avg < 6.5 ~ 45,
    avg >= 6.5 ~ 40,
  )) %>%  

  mutate(difference = (RepVotesMajorPercent - Rankings_code)) %>% 
  mutate(incumbent = case_when(winner_candidate_inc == "Incumbent" ~ "0",
                               winner_candidate_inc == "Challenger" ~ "1"))

plot(expert_incumbent$incumbent, expert_incumbent$DemVotesMajorPercent)
#fit3 <- lm(DemVotesMajorPercent ~ incum, data = expert_incumbent)
#summary(fit3)

cd114_rank <- cd114 %>% 
  left_join(expert_incumbent, by=c("district_num", "State"))
cd114_simp_rank <- ms_simplify(cd114_rank, keep = 0.01, keep_shapes = T)
```
The map below shows the expert rankings for each state on a scale of 1 to 7 (Solid D to Solid R). This map follows a fairly similar trend as the actual vote share. To more directly see the relationship between expert rankings and vote share, I converted the rankings to vote share in the following map.

```{r, include = T}
ggplot() +
  geom_sf(data = cd114_simp_rank, aes(fill = avg),
          inherit.aes = FALSE, alpha = 0.9) +
  scale_fill_gradient2(low = "blue", high = "red", 
                       limits = c(1, 7),
                       name = "Ranking") +
  theme_void() + 
  coord_sf(xlim = c(-172.27, -66.57), ylim = c(18.55, 71.23), expand = FALSE) + 
  labs(title = "Expert Predictions (2018)",
       subtitle = "Republican (Red) -- Democrat (Blue)") +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())
```

# Mapping Difference Between Actual Vote and Expert Ranking
For this map, I converted the seven categories into a related vote share for democrats: 
Solid D = 60
Likely D =  55
Lean D = 52.5
Toss up = 50
Lean R = 47.5
Likely R = 45
Solid R = 40

```{r, include = T}
ggplot() +
  geom_sf(data = cd114_simp_rank, aes(fill = difference),
          inherit.aes = FALSE, alpha = 0.9) +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", 
                       limits = c(-100, 100),
                       name = "Vote Share Margin") +
  theme_void() + 
  coord_sf(xlim = c(-172.27, -66.57), ylim = c(18.55, 71.23), expand = FALSE) + 
  labs(title = "Vote Share Margin by District (2018)",
       subtitle = "Republican (Red) -- Democrat (Blue)") +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())
```
# Analysis

Looking at these three maps, all three follow the same general trends across the country. One of the most significant disparities is with how unchallenged candidates impact the vote share. For example, in New York’s 16th district, there was a 100% democratic vote share. This is because the democratic candidate ran unopposed and therefore there were no republican votes. However, in the expert rankings map, this would only register as a Solid D and therefore only get 60% of the votes. By hardcoding these values in it makes it difficult to measure and map the validity of expert rankings to the actual vote share of the district. 


```{r, include = F}
# Result_counter <- 0
# # Result_counter is 64 reps
# for (i in 1:nrow(expert_incumbent)) 
# {
#   if (expert_incumbent$Result_code[i] == "Solid R" || expert_incumbent$Result_code[i] == "Likely R" || expert_incumbent$Result_code[i] == "Lean R" )
#   {
#      Result_counter <- Result_counter + 1
#   }
# }
# 
# Rank_counter <- 0
# # Rank_counter is 79 reps
# for (i in 1:nrow(expert_incumbent$Result_code)) 
# {
#   if (expert_incumbent$Rankings_code[i] == "Solid R" || expert_incumbent$Rankings_code[i] == "Likely R" || expert_incumbent$Rankings_code[i] == "Lean R" )
#   {
#      Rank_counter <- Rank_counter + 1
#   }
# }

# Rank_toss <- sum(expert_incumbent$Rankings_code == "Toss up")
# Result_toss <- sum(expert_incumbent$Result_code == "Toss up")
# Rank_solidD <- sum(expert_incumbent$Rankings_code == "Solid D")
# Rank_likelyD <- sum(expert_incumbent$Rankings_code == "Likely D")
# Rank_leanD <- sum(expert_incumbent$Rankings_code == "Lean D")
# Results_solidD <- sum(expert_incumbent$Result_code == "Solid D")
# Results_likelyD <- sum(expert_incumbent$Result_code == "Likely D")
# Results_leanD <- sum(expert_incumbent$Result_code == "Lean D")
# Rank_solidR <- sum(expert_incumbent$Rankings_code == "Solid R")
# Rank_likelyR <- sum(expert_incumbent$Rankings_code == "Likely R")
# Rank_leanR <- sum(expert_incumbent$Rankings_code == "Lean R")
# Results_solidR <- sum(expert_incumbent$Result_code == "Solid R")
# Results_likelyR <- sum(expert_incumbent$Result_code == "Likely R")
# Results_leanR <- sum(expert_incumbent$Result_code == "Lean R")
# 
# 
# Sum_df <- data.frame(Categories = c("Solid D", "Likely D", "Lean D", "Toss up", "Lean R", "Likely R", "Solid R"),
#                       Rankings_Sum = c(Rank_solidD, Rank_likelyD, Rank_leanD, Rank_toss, Rank_leanR, Rank_likelyR, 
#                                       Rank_solidR),
#                      Result_Sum = c(Results_solidD, Results_likelyD, Results_leanD, Result_toss, Results_leanR, 
#                                      Results_likelyR, Results_solidR)) 

# cd114_expert <- cd114 %>% 
#   left_join(expert_ratings, by=c("district_num", "State"))
# cd114_ex <- ms_simplify(cd114_expert, keep = 0.01, keep_shapes = T)
# 
# ggplot() +
#   geom_sf(data = cd114_ex, aes(fill = avg_rating),
#           inherit.aes = FALSE, alpha = 0.9) +
#   scale_fill_gradient2(low = "blue", mid = "white", high = "red", 
#                        limits = c(1, 7),
#                        name = "Vote Share Margin") +
#   theme_void() + 
#   coord_sf(xlim = c(-172.27, -66.57), ylim = c(18.55, 71.23), expand = FALSE) + 
#   labs(title = "Vote Share Margin by District (2018)",
#        subtitle = "Republican (Red) -- Democrat (Blue)") +
#   theme(axis.title.x=element_blank(),
#         axis.text.x=element_blank(),
#         axis.ticks.x=element_blank(),
#         axis.title.y=element_blank(),
#         axis.text.y=element_blank(),
#         axis.ticks.y=element_blank())


  

```


# Model Updates

This week, I also formalized my model from the collection of variables analyzed the past few weeks. After looking at economic fundamentals in week 2, I decided to add another variable, CPI, which proved to be the strongest predictor of vote share compared to GDP, RDI, and unemployment. In week 2, I also noticed that economic predictors appeared strongest in Q7. For this reason, I used CPI from October of the election year in my model (Healy and Lenz). In week 3, I looked at polling averages. I found that polling was strongest the month prior to the election, so filtered for polls from October to the election. In this model, my predicted Republican Vote share is 48.21% and my predicted Democratic vote share is 49.95%. These values use the most [recent generic ballot](https://projects.fivethirtyeight.com/polls/generic-ballot/) polls. However, for both of these values, my adjusted R-squared is about 0.2 which is very low, and indicates that these predictions do not hold much statistical significance. 

```{r, include = T}
# Most Recent Model:
## CPI and October polls
fundamentals_polls.Oct <- read_csv("fundamentals_polls.Oct.csv")

lm_fun_polls.D <- lm(D_majorvote_pct ~ CPIAUCSL + DSPIC_change_pct + D_support, data = fundamentals_polls.Oct)
#summary(lm_fun_polls.D)
lm_fun_polls.R <- lm(R_majorvote_pct ~ CPIAUCSL + DSPIC_change_pct + D_support, data = fundamentals_polls.Oct)
#summary(lm_fun_polls.R)


lm_fun_polls.R <- lm(R_totalvote_pct ~ CPIAUCSL.ave + R_support, data = fundamentals_polls.Oct)
#summary(lm_fun_polls.R)
lm_fun_polls.D <- lm(D_majorvote_pct ~ CPIAUCSL.ave + D_support, data = fundamentals_polls.Oct)
#summary(lm_fun_polls.D)

data_2022.R <- data.frame(CPIAUCSL.ave = 295.62, R_support = 44.1)
# predict(lm_fun_polls.R, newdata = data_2022.R) 
# 48.21145

data_2022.D <- data.frame(CPIAUCSL.ave = 295.62, D_support = 45.4)
# predict(lm_fun_polls.D, newdata = data_2022.D)
# 49.95024 
```

# Moving Forward

After looking at expert ratings at the district level, this data will help me construct a district level seat share model. However, I will not be creating a district level model this week as expert ratings would be the only variable I could add, making for a poor model. Although, I will also consider adding a variable around incumbency in my model. 

```{r, include = F}
# New Model:

# district_polls <- read_csv("dist_polls_2018-2022.csv") %>% 
#   separate(end_date, into = c("month", "day", "year"), sep = "/") %>% 
#   filter(month == 10)
# 
#  %>% 
#   clean_names() %>% 
#   select(race_year, state, area, dem_votes_major_percent, rep_votes_major_percent) %>% 
#   rename("year" = "race_year") %>% 
#   separate(area, into = c("area", "district"), sep = " ") %>% 
#   select(-area) %>% 
#   mutate(district = case_when(
#     district == "Large" ~ "AL",
#     TRUE ~ district
#   ))
# 
# 
# idk <- left_join(expert_ratings, historical_results, by = c('year', 'state', 'district'))
# 
# test <- merge(fundamentals_polls.Oct, idk, by = 'year')
# train_data <- idk %>% 
#   group_by(state, district) %>% 
#   filter(n() > 1) %>% # Filtering out single data rows
#   group_nest() %>% 
#   mutate(data = map(data, ~unnest(., cols = c())))
# 
# test_data <- idk %>% 
#   filter(year == 2022) %>% 
#   group_by(state, district) %>% 
#   group_nest() %>% 
#   mutate(data = map(data, ~unnest(., cols = c())))
# 
# model_results <- models %>% 
#   mutate(r_squared = map_dbl(model, ~summary(.x)$r.squared))
# 
# models <- train_data %>% 
#   mutate(model = map(data, ~lm(dem_votes_major_percent ~ avg_rating + CPIAUCSL.ave + D_support, # this is where you add your other variables
#                                   data = test))) 
# pred_2022 <- test_data %>%
#   
#   # inner join as there may not be historical models for some districts
#   inner_join(models, by = c("state", "district")) %>% 
#   mutate(pred = map_dbl(.x = model, .y = data, ~predict(object = .x, newdata = as.data.frame(.y)))) %>%
#   select(state, district, pred)
```

